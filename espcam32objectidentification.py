# -*- coding: utf-8 -*-
"""espcam32objectIdentification.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1M-In6R3d7zvEz_VOnyneYzBWmmZV1dYP
"""

import zipfile
import os

zip_path = "/content/dataset3.zip"
extract_path = "/content/et"

# Create the extraction directory if it doesn't exist
os.makedirs(extract_path, exist_ok=True)

with zipfile.ZipFile(zip_path, 'r') as zip_ref:
    zip_ref.extractall(extract_path)

print(f"Zip file extracted to: {extract_path}")

import tensorflow as tf
from keras.applications import MobileNetV2
from keras.models import Model
from keras.layers import Dense, GlobalAveragePooling2D
from tensorflow.keras.preprocessing.image import ImageDataGenerator
import numpy as np
import os
import math

train_data_dir = "/content/et"

img_height =160
img_width = 160
batchsize =8
num_classes =2

#data augmentation
Train_data_gen = ImageDataGenerator(
    rescale =1/255.0,
    rotation_range=25,
    width_shift_range = 0.2,
    height_shift_range = 0.2,
    shear_range=0.2,
    zoom_range=0.2,
    horizontal_flip= True,
    fill_mode='nearest',
    validation_split = 0.2
);

#loadinng the training data using the image data generator classified above
train_dataGenerator = Train_data_gen.flow_from_directory(train_data_dir,
                                                         target_size=(img_height,img_width),
                                                         batch_size = batchsize,
                                                         class_mode='categorical',
                                                         classes=[d for d in os.listdir(train_data_dir) if os.path.isdir(os.path.join(train_data_dir, d)) and not d.startswith('.')], # Provide a list of class names
                                                         subset ='training'
                                                         )
validation_dataGenerator = Train_data_gen.flow_from_directory(train_data_dir,
                                                         target_size=(img_height,img_width),
                                                         batch_size = batchsize,
                                                         class_mode='categorical',
                                                         classes=[d for d in os.listdir(train_data_dir) if os.path.isdir(os.path.join(train_data_dir, d)) and not d.startswith('.')], # Provide a list of class names
                                                         subset ='validation'
                                                         )
# Making the model using MobileNetV2 and setting the madel traing false to add pooling and dense layers.
base_model = MobileNetV2( weights ='imagenet', include_top=False, input_shape=(img_height,img_width,3));

base_model.trainable= False;

x = base_model.output
x = GlobalAveragePooling2D()(x)
x = Dense( 128, activation='relu')(x)
prediction = Dense(num_classes,activation='softmax')(x)

model = Model(inputs = base_model.input, outputs =prediction)

model.compile(optimizer='adam',loss='categorical_crossentropy', metrics=['accuracy'])

# Calculate steps per epoch and validation step
steps_per_epoch = math.ceil(train_dataGenerator.samples / batchsize)
validation_steps = math.ceil(validation_dataGenerator.samples / batchsize)

model.fit(train_dataGenerator,
          epochs=10,
          steps_per_epoch=steps_per_epoch,
          validation_steps=validation_steps,
          validation_data=validation_dataGenerator # Corrected argument name
          )
data_loss,accuracy_validation=model.evaluate(validation_dataGenerator)
print(f"Validation Loss: {data_loss} Validation Accuracy: {accuracy_validation}")

model.save('airpod_box_classifier.h5')
#converts float32 to 8 bit integer
def representative_dataset():
    for _ in range(100):
        data = next(validation_dataGenerator)[0]
        yield [data.astype(np.float32)]

# Convert to TFLite
converter = tf.lite.TFLiteConverter.from_keras_model(model)
converter.optimizations = [tf.lite.Optimize.DEFAULT]
converter.representative_dataset = representative_dataset
converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]
converter.inference_input_type = tf.int8
converter.inference_output_type = tf.int8
tflite_model = converter.convert()

# Save TFLite model
with open('airpods_box_model.tflite', 'wb') as f:
    f.write(tflite_model)

# Convert to C array for ESP32-CAM
def convert_to_c_array(tflite_path, output_path):
    with open(tflite_path, 'rb') as f:
        model_content = f.read()
    with open(output_path, 'w') as f:
        f.write('#ifndef MODEL_H_\n#define MODEL_H_\n\n')
        f.write('const unsigned char model_tflite[] = {\n')
        for i, byte in enumerate(model_content):
            if i % 12 == 0:
                f.write('    ')
            f.write(f'0x{byte:02x}')
            if i < len(model_content) - 1:
                f.write(', ')
            if (i + 1) % 12 == 0:
                f.write('\n')
        f.write('\n};\n\n')
        f.write(f'const unsigned int model_tflite_len = {len(model_content)};\n')
        f.write('#endif\n')

convert_to_c_array('airpods_box_model.tflite', 'model.h')
print("Model converted and saved as model.h")

# Test TFLite model
interpreter = tf.lite.Interpreter(model_path='airpods_box_model.tflite')
interpreter.allocate_tensors()
input_details = interpreter.get_input_details()
output_details = interpreter.get_output_details()
print("Input shape:", input_details[0]['shape'])
print("Input type:", input_details[0]['dtype'])
print("Output shape:", output_details[0]['shape'])
print("Output type:", output_details[0]['dtype'])
print("Input quantization (scale, zero_point):", input_details[0]['quantization'])
print("Output quantization (scale, zero_point):", output_details[0]['quantization'])

from google.colab import drive
drive.mount('/content/drive')

import os

extracted_dataset_path = "/content/et"

# List all items in the extracted dataset directory
items = os.listdir(extracted_dataset_path)

# Filter for directories (which represent classes)
class_directories = [item for item in items if os.path.isdir(os.path.join(extracted_dataset_path, item))]

# Print the number of class directories found and their names
print(f"Found {len(class_directories)} class directories:")
for class_dir in class_directories:
    print(class_dir)